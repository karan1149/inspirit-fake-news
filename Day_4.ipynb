{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "25LTrZKbEIcN"
   },
   "source": [
    "# Day 4: Final Fake News Classification Model and Analysis\n",
    "\n",
    "Over the past few days, we've seen a few different approaches for featurizing the URL and HTML data for a website for fake news classification. On this final day, we review these approaches, combine them together, and refine our final model. We'll create a demo that performs fake news classification on new unseen websites, scraping the websites in real time. Finally, we'll also evaluate on the test set that we have been holding out.\n",
    "\n",
    "Run the below cell to get started and load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "qxV2fxCpUlzL",
    "outputId": "5fe8d6c4-1c5d-49e3-a7c6-d1499b27427b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/772 [00:00<00:39, 19.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 772\n",
      "Number of val examples: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 763/772 [09:40<00:01,  7.57it/s]  "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import pickle\n",
    "\n",
    "import requests, io, zipfile\n",
    "# Download class resources...\n",
    "r = requests.get(\"https://www.dropbox.com/s/2pj07qip0ei09xt/inspirit_fake_news_resources.zip?dl=1\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()\n",
    "\n",
    "basepath = '.'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "with open(os.path.join(basepath, 'sample_train_val_data.pkl'), 'rb') as f: # TODO change this to actual data\n",
    "  train_data, val_data = pickle.load(f)\n",
    "  \n",
    "print('Number of train examples:', len(train_data))\n",
    "print('Number of val examples:', len(val_data))\n",
    "\n",
    "def get_description_from_html(html):\n",
    "  soup = bs(html)\n",
    "  description_tag = soup.find('meta', attrs={'name':'og:description'}) or soup.find('meta', attrs={'property':'description'}) or soup.find('meta', attrs={'name':'description'})\n",
    "  if description_tag:\n",
    "    description = description_tag.get('content') or ''\n",
    "  else: # If there is no description, return empty string.\n",
    "    description = ''\n",
    "  return description\n",
    "\n",
    "def get_descriptions_from_data(data):\n",
    "  # A dictionary mapping from url to description for the websites in \n",
    "  # train_data.\n",
    "  descriptions = []\n",
    "  for site in tqdm(data):\n",
    "    ### YOUR CODE HERE ###\n",
    "    url, html, label = site\n",
    "    descriptions.append(get_description_from_html(html))\n",
    "    ### END CODE ###\n",
    "  return descriptions\n",
    "\n",
    "\n",
    "train_descriptions = get_descriptions_from_data(train_data)\n",
    "val_descriptions = get_descriptions_from_data(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JfKyVvKFXHkF"
   },
   "source": [
    "Before we begin, fill in the following function, which trains and evaluates a logistic regression model given train_X, train_y, val_X, and val_y. Print train accuracy, val accuracy, confusion matrix, precision, recall, and F1-score, just as we have been doing the past few days (~5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaPrxHXRXdnU"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(train_X, train_y, val_X, val_y):\n",
    "  model = LogisticRegression()\n",
    "  model.fit(train_X, train_y)\n",
    "  \n",
    "  ### YOUR CODE HERE ###\n",
    "\n",
    "  train_y_pred = model.predict(train_X)\n",
    "  print('Train accuracy', accuracy_score(train_y, train_y_pred))\n",
    "\n",
    "  val_y_pred = model.predict(val_X)\n",
    "  print('Val accuracy', accuracy_score(val_y, val_y_pred))\n",
    "\n",
    "  print('Confusion matrix:')\n",
    "  print(confusion_matrix(val_y, val_y_pred))\n",
    "\n",
    "  prf = precision_recall_fscore_support(val_y, val_y_pred)\n",
    "\n",
    "  print('Precision:', prf[0][1])\n",
    "  print('Recall:', prf[1][1])\n",
    "  print('F-Score:', prf[2][1])\n",
    "  \n",
    "  ### END CODE HERE ###\n",
    "  \n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLHB6SdDU-Km"
   },
   "source": [
    "Our first approach to featurizing our data involved looking only at URLs, specifically domain name extensions. We discovered that this achieved about 60% accuracy, with many false negatives for fake news websites with an innocuous domain name extension like \".com\". This accuracy wasn't great, but it gave us a baseline to improve upon.\n",
    "\n",
    "We next moved on to keyword-based featurization, which combined the above domain name extension features with normalized counts (extracted from HTML) for a list of specific words. Given the functions for featurizing data before and our new helper function *train_and_evaluate_model*, train and evaluate a model on top of keyword (combined with domain name extension) featurization (~5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "O82N2Xi0CJHb",
    "outputId": "4436813e-d337-4444-e205-2ff06b51d132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.805699481865285\n",
      "Val accuracy 0.8111111111111111\n",
      "Confusion matrix:\n",
      "[[40 10]\n",
      " [ 7 33]]\n",
      "Precision: 0.7674418604651163\n",
      "Recall: 0.825\n",
      "F-Score: 0.7951807228915662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(data, featurizer):\n",
    "    X = []\n",
    "    y = []\n",
    "    for datapoint in data:\n",
    "        url, html, label = datapoint\n",
    "        # We convert all text in HTML to lowercase, so <p>Hello.</p> is mapped to\n",
    "        # <p>hello</p>. This will help us later when we extract features from \n",
    "        # the HTML, as we will be able to rely on the HTML being lowercase.\n",
    "        html = html.lower() \n",
    "        y.append(label)\n",
    "\n",
    "        features = featurizer(url, html)\n",
    "\n",
    "        # Gets the keys of the dictionary as descriptions, gets the values\n",
    "        # as the numerical features. Don't worry about exactly what zip does!\n",
    "        feature_descriptions, feature_values = zip(*features.items())\n",
    "\n",
    "        X.append(feature_values)\n",
    "\n",
    "    return X, y, feature_descriptions\n",
    "  \n",
    "# Gets the log count of a phrase/keyword in HTML (transforming the phrase/keyword\n",
    "# to lowercase).\n",
    "def get_normalized_count(html, phrase):\n",
    "    return math.log(1 + html.count(phrase.lower()))\n",
    "\n",
    "# Returns a dictionary mapping from plaintext feature descriptions to numerical\n",
    "# features for a (url, html) pair.\n",
    "def keyword_featurizer(url, html):\n",
    "    features = {}\n",
    "    \n",
    "    # Same as before.\n",
    "    features['.com domain'] = url.endswith('.com')\n",
    "    features['.org domain'] = url.endswith('.org')\n",
    "    features['.net domain'] = url.endswith('.net')\n",
    "    features['.info domain'] = url.endswith('.info')\n",
    "    features['.org domain'] = url.endswith('.org')\n",
    "    features['.biz domain'] = url.endswith('.biz')\n",
    "    features['.ru domain'] = url.endswith('.ru')\n",
    "    features['.co.uk domain'] = url.endswith('.co.uk')\n",
    "    features['.co domain'] = url.endswith('.co')\n",
    "    features['.tv domain'] = url.endswith('.tv')\n",
    "    features['.news domain'] = url.endswith('.news')\n",
    "    \n",
    "    keywords = ['trump', 'biden', 'clinton', 'sports', 'finance']\n",
    "    \n",
    "    for keyword in keywords:\n",
    "      features[keyword + ' keyword'] = get_normalized_count(html, keyword)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "keyword_train_X, train_y, _ = prepare_data(train_data, keyword_featurizer)\n",
    "keyword_val_X, val_y, _ = prepare_data(val_data, keyword_featurizer)\n",
    "\n",
    "train_and_evaluate_model(keyword_train_X, train_y, keyword_val_X, val_y)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGg-HE9zYUf7"
   },
   "source": [
    "We can see that we are achieving significantly better accuracy and better balance between false negatives and false positives. As expected, it looks like actually making use of the content of the HTML is useful.\n",
    "\n",
    "Another way to take advantage of the HTML is to extract a bag-of-words (BOW) featurization from the meta description stored in the HTML. As before, train and evaluate this approach with our helper function *train_and_evaluate_model* (~5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "gr59XamsY0Yt",
    "outputId": "e3b4347d-1287-42eb-de6b-4b1a2b27a2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.8782383419689119\n",
      "Val accuracy 0.7\n",
      "Confusion matrix:\n",
      "[[25 25]\n",
      " [ 2 38]]\n",
      "Precision: 0.6031746031746031\n",
      "Recall: 0.95\n",
      "F-Score: 0.7378640776699029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=300)\n",
    "\n",
    "vectorizer.fit(train_descriptions)\n",
    "\n",
    "def vectorize_data_descriptions(data_descriptions, vectorizer):\n",
    "  X = vectorizer.transform(data_descriptions).todense()\n",
    "  return X\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Note that you can use train_y and val_y from before, since these are the\n",
    "# same for both the keyword approach and the BOW approach.\n",
    "\n",
    "bow_train_X = vectorize_data_descriptions(train_descriptions, vectorizer)\n",
    "bow_val_X = vectorize_data_descriptions(val_descriptions, vectorizer)\n",
    "\n",
    "train_and_evaluate_model(bow_train_X, train_y, bow_val_X, val_y)\n",
    "\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fbSxskAMZkl4"
   },
   "source": [
    "We can see that we are getting similar results, without necessarily using the same information as the keywords-based approach. We then asked whether we could do better by making use of word vectors, which encode the meaning of different words. We found that averaging the word vectors for words in the meta description was a useful approach. As before, complete the code for training and evaluation of this approach (~5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "GERdCc6_aCtt",
    "outputId": "88cd6608-2488-4f58-9822-02b0d320d8f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [00:57, 15.0MB/s]                           \n",
      "100%|█████████▉| 399649/400000 [00:45<00:00, 8793.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.8639896373056994\n",
      "Val accuracy 0.7111111111111111\n",
      "Confusion matrix:\n",
      "[[30 20]\n",
      " [ 6 34]]\n",
      "Precision: 0.6296296296296297\n",
      "Recall: 0.85\n",
      "F-Score: 0.723404255319149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "VEC_SIZE = 300\n",
    "glove = GloVe(name='6B', dim=VEC_SIZE)\n",
    "\n",
    "# Returns word vector for word if it exists, else return None.\n",
    "def get_word_vector(word):\n",
    "    try:\n",
    "      return glove.vectors[glove.stoi[word.lower()]].numpy()\n",
    "    except KeyError:\n",
    "      return None\n",
    "\n",
    "def glove_transform_data_descriptions(descriptions):\n",
    "    X = np.zeros((len(descriptions), VEC_SIZE))\n",
    "    for i, description in enumerate(descriptions):\n",
    "        found_words = 0.0\n",
    "        description = description.strip()\n",
    "        for word in description.split(): \n",
    "            vec = get_word_vector(word)\n",
    "            if vec is not None:\n",
    "                ### YOUR CODE HERE ###\n",
    "                # Increment found_words and add vec to X[i].\n",
    "                found_words += 1\n",
    "                X[i] += vec\n",
    "                ### END CODE HERE ###\n",
    "        # We divide the sum by the number of words added, so we have the\n",
    "        # average word vector.\n",
    "        if found_words > 0:\n",
    "            X[i] /= found_words\n",
    "            \n",
    "    return X\n",
    "  \n",
    "  \n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Note that you can use train_y and val_y from before, since these are the\n",
    "# same for both the keyword approach and the BOW approach.\n",
    "  \n",
    "glove_train_X = glove_transform_data_descriptions(train_descriptions)\n",
    "glove_val_X = glove_transform_data_descriptions(val_descriptions)\n",
    "\n",
    "train_and_evaluate_model(glove_train_X, train_y, glove_val_X, val_y)\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1MMnLlRaqlz"
   },
   "source": [
    "Again, solid results using a completely different approach.\n",
    "\n",
    "## Combining Approaches\n",
    "\n",
    "A natural question to ask now is whether we can combine the above featurization approaches for improved results. It turns out we can, by concatenating the feature vectors for each website produced using each of the three above approaches. Below we provide a handy helper function that takes in a list of multiple train_X produced using different featurization approaches and combines them into *combined_train_X*. It does this for val_X as well.\n",
    "\n",
    "As an example, if our keyword-based approach has 15 features, our BOW approach has 300, and our GloVe approach has 300, then our combined approach has 615 features.\n",
    "\n",
    "Complete the below code for training and evaluating the combined approach (~8 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "iVH271oPWEnn",
    "outputId": "f83d932a-6145-4425-9b1f-38b47ae3a6ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.917098445595855\n",
      "Val accuracy 0.8\n",
      "Confusion matrix:\n",
      "[[35 15]\n",
      " [ 3 37]]\n",
      "Precision: 0.7115384615384616\n",
      "Recall: 0.925\n",
      "F-Score: 0.8043478260869567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def combine_features(X_list):\n",
    "  return np.concatenate(X_list, axis=1)\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "# First, produce combined_train_X and combined_val_X using 2 calls to \n",
    "# combine_features, using keyword_train_X, bow_train_X, glove_train_X\n",
    "# and keyword_val_X, bow_val_X, glove_val_X from before.\n",
    "\n",
    "combined_train_X = combine_features([keyword_train_X, bow_train_X, glove_train_X])\n",
    "combined_val_X = combine_features([keyword_val_X, bow_val_X, glove_val_X])\n",
    "\n",
    "train_and_evaluate_model(combined_train_X, train_y, combined_val_X, val_y)\n",
    "\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B24s94fGcmhV"
   },
   "source": [
    "Now, make changes to the keyword, BOW, and GloVe featurization code above to improve performance. For example, add keywords to the keyword featurization code, play around with different values for *max_features* and other parameters for [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), and try summing instead of averaging word vectors.\n",
    "\n",
    "Once you feel satisfied with your results, play around with the below demo, which scrapes a new website live and runs your trained classification model on it! The below code assumes you have run the code above and have not changed the names of any of the featurization functions. It combines the three featurization approaches. Go through the code below and make sure you understand what it is doing! Feel free to also make changes (e.g. if you only want to use two featurization approaches) (~15 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iibMAoVacRbb"
   },
   "outputs": [],
   "source": [
    "#@title Live Fake News Classification Demo { run: \"auto\", display-mode: \"both\" }\n",
    "def get_data_pair(url):\n",
    "  if not url.startswith('http'):\n",
    "      url = 'http://' + url\n",
    "  url_pretty = url\n",
    "  if url_pretty.startswith('http://'):\n",
    "      url_pretty = url_pretty[7:]\n",
    "  if url_pretty.startswith('https://'):\n",
    "      url_pretty = url_pretty[8:]\n",
    "      \n",
    "  # Scrape website for HTML\n",
    "  response = requests.get(url, timeout=10)\n",
    "  htmltext = response.text\n",
    "  \n",
    "  return url_pretty, htmltext\n",
    "\n",
    "curr_url = \"nytimes.com\" #@param {type:\"string\"}\n",
    "\n",
    "url, html = get_data_pair(curr_url)\n",
    "\n",
    "def featurize_data_pair(url, html):\n",
    "  # Approach 1.\n",
    "  keyword_X = keyword_featurizer(url, html)\n",
    "\n",
    "  # Approach 2.\n",
    "  description = get_description_from_html(html)\n",
    "  \n",
    "  bow_X = vectorize_data_descriptions([description])\n",
    "  \n",
    "  # Approach 3.\n",
    "  glove_X = glove_transform_data_descriptions([description])\n",
    "  \n",
    "  X = combine_features(keyword_X, bow_X, glove_X)\n",
    "  \n",
    "  return X\n",
    "\n",
    "curr_X = featurize_data_pair(url, html)\n",
    "\n",
    "model = train_and_evaluate_model(combined_train_X, train_y, combined_val_X, val_y)\n",
    "\n",
    "curr_y = model.predict(curr_X)[0]\n",
    "  \n",
    "  \n",
    "if curr_y < .5:\n",
    "  print(curr_url, 'appears to be real.')\n",
    "else:\n",
    "  print(curr_url, 'appears to be fake.')\n",
    "  \n",
    "print('Output prediction:', curr_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ncfKGpc4tTEa"
   },
   "source": [
    "Note that we can interpret the output prediction as a belief probability: an output of 0.9 suggests the model believes there is a 90% chance the website is fake.\n",
    "\n",
    "After playing around with your model live, do you have any ideas for how to improve it? Make changes above and see what impact they have on the final model.\n",
    "\n",
    "Once you are done, we will provide code to test your model on the test data. Note that you should only run on the test data once. When you have results on the test data, share with your instructor, as the team with the best results will be rewarded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMKg65vQdNqT"
   },
   "outputs": [],
   "source": [
    "### PUT TEST CODE HERE ###\n",
    "\n",
    "with open(os.path.join(basepath, 'sample_test_data.pkl'), 'rb') as f: # TODO change this to actual data\n",
    "  test_data = pickle.load(f)\n",
    "  \n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYNRu7vNdW55"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day 4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
